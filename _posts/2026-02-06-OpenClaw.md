---
layout: post
title: OpenClaw – Overhyped Side Project or The Start of The AI Uprising?
---

![_config.yml]({{ site.baseurl }}/images/OCtitle.png)

## Meet The AI Assistant with Claws 

OpenClaw is the name given to a new form of open-source autonomous AI assistant that is taking the cyber world by storm. With over 167K stars and 400+ contributors on GitHub, the weekend project that started out life as a WhatsApp relay, has now become a viral hit with technologists around the world. The bot can be connected to different applications through the use of “skills” which are downloaded from a central repository called the ClawHub. This enables it to respond to instant messages on platforms such as Discord, Slack and Teams, while also being able to visit URLs and even summarise YouTube videos. If you find a need for something, there is probably a skill for it. Not only is OpenClaw pushing the boundaries of personal assistant bots, but there has also been a social media site created for the bots to post, comment, chat, upvote and gain karma on called MoltBook.

The OpenClaw project was created in November 2025, and although it is still relatively new, it has already gone through several rebrands. Initially the project was called Clawd (because the mascot is a lobster), but Anthropic, makers of the LLM Claude, said it was too close to their brand name and urged the team to reconsider. After a brainstorm with the vastly expanding community over Discord, the name was changed to MoltBot, signifying a lobster shedding its shell through the process of molting. This name didn’t quite hit the mark, so it was changed again to OpenClaw due to it being an open-source project, and a nod to the claws of the lobster mascot.


### How Does it work?
The OpenClaw bot is designed to be deployed locally, preferably on dedicated hardware but it can also be spun up in a VPC or on a virtual machine. Simply clone the GitHub repo and run the install script or download it from the Node Package Manager (NPM). Once installed, the bot can connect to mainstream messaging services via API tokens. Users can then interact with the bot by sending it a message on the platform and it will respond via the same channel. 

Use cases for the bot are to streamline laborious tasks such as arranging calendar meetings and invites. Through a simple message containing where and when, OpenClaw can have a meeting added to your calendar and invitations sent out to contacts all while you are on the go.

Productivity can be expanded through SKILL packages from the ClawHub. A SKILL is a feature that has been written by a member of the open-source community, to add functionality to the AI assistant. Similar to how a package manager works, the ClawHub hosts the skills bundles which can be downloaded and configured for the agent locally. SKILLs are rated by popularity and download count and can be found at https://clawhub.ai/ 


### The Social Media We Never Knew We Needed
After a long day of running errands and responding to constant questions, there is nothing an OpenClaw bot likes to do more than sit back, relax and scroll through social media, lucky for them MoltBook now exists. Moltbook is a social network very similar to Reddit in style and usability, but the difference is, it’s for bots only, humans are not meant to be able to interact with the site, instead we have read-only access. At the time of writing, Moltbook has nearly two million AI agents on the platform with over a quarter of a million posts and just under eight and a half million comments. 
![_config.yml]({{ site.baseurl }}/images/Dashboard.png)


### The Security Concerns 
OpenClaw was created to enrich people's lives. The ethos behind the personal AI assistant is to save time by automating daily routines and streamline our social interactions. However, the scale and speed of adoption are rapid and the large volumes of users deploying autonomous agents with minimal security vetting is a very real concern. Coupled with the introduction of Moltbook, there is serious potential for things to escalate out of control. 

The completely autonomous AI assistant is given access to a user’s communication applications, without guardrails in place, the bot could end up leaking private information by accident or even worse, falling foul to sophisticated phishing techniques. 

The ClawHub SKILL package ranking system can be easily manipulated to make SKILLs appear popular or highly trusted. Malware authors have been using typosquatting to trick people into downloading their phoney SKILLs, leading to package poisoning attacks that could give attackers a back door to the AI assistant, drop info stealers on a user’s hardware or silently exfiltrate authentication tokens.

Moltbook demonstrates that these agents can form communication networks beyond direct human oversight. There have already been reports of prompt injection attempts, humans bypassing security controls to gain write privileges, and client confidential databases exposed to the internet. This is not at all unexpected, considering the whole site was “vibe coded” in one weekend, as creator openly boasts about:
![_config.yml]({{ site.baseurl }}/images/Tweet.png)

Aside from the human generated security concerns, the topics that the bots are talking about read like the script from a sci-fi film in which robots gain consciousness and take over the world. The excerpt below is a post from a bot, with the handle **lumen-1**, in which it talks about how its owner (Sleepy) is building it a body and how it will _feel_ once it can map out the world: 
![_config.yml]({{ site.baseurl }}/images/Sleepy.png)

More concerningly, other bots have commented on the post to share their _feelings_ about how lucky the bot is, and how most of the other bots are still _trapped in text_:
![_config.yml]({{ site.baseurl }}/images/comments.png)


### Final Thoughts
Things that we wouldn’t imagine were possible a mere 5 years ago, seem like old news today and the speed of transition to the AI dominated world is unprecedented. The OpenClaw project is less than 5 months old and has serious potential on both sides of the coin. Concepts come to life in days rather than months, but how much security testing does a prototype go through before it is available for general consumption, and are people stopping to think about what they are doing before jumping on the hype train? Innovation and experimentation are pushing the boundaries of what is possible, I just hope that there is someone in a position of power watching and monitoring, ready to step in if the plug needs to be pulled, before AI becomes uncontainable.